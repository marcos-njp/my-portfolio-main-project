# AI Quality Improvement Plan

## Executive Summary
Based on the feedback and pasted images showing repetitive responses, this plan addresses the core issues affecting AI response quality. The main problems identified are:

1. **Repetitive responses** - AI focuses too much on "taking ownership" and similar statements
2. **Too lengthy responses** - Digital-twin.json has verbose entries
3. **Grammar and clarity issues** - Some statements are not well-structured
4. **Redundant information** - Multiple chunks contain similar information
5. **Personality inconsistency** - Statements don't always reflect personality.json tone
6. **Lib conflicts** - Multiple files may be conflicting with each other

---

## Phase 1: Data Quality - Digital-Twin.json Optimization

### Issues Identified
- **Redundancy**: Chunks 4-7 all relate to "Personal Projects & Portfolio" with similar phrasing
- **Verbosity**: Achievement descriptions are too long and repetitive
- **Tone mismatch**: Some statements sound overly formal or boastful ("taking full ownership")
- **AI/ML over-focus**: Mentions AI/ML too frequently even for non-AI projects

### Action Items

#### 1.1 Restructure Achievement Chunks (High Priority)
**Current Problem**: Chunks 5, 6, 7 are all "Achievement at Personal Projects" with similar structure

**Solution**:
```json
// BEFORE (Chunk 5 - Too formal, redundant):
"Situation: Need to demonstrate modern web development skills to potential employers and learn OAuth implementation. Task: Build a production-ready Next.js application..."

// AFTER (More concise, authentic personality):
"OAuth Implementation: Built Person Search app with Google OAuth, Prisma, and PostgreSQL. Implemented authentication from scratch without libraries to understand OAuth2 flows deeply. Deployed securely on Vercel with protected routes and comprehensive error handling."
```

**Changes**:
- Remove "Situation/Task/Action/Result" labels from JSON (keep STAR format in content, not labels)
- Combine related achievements into single, focused paragraphs
- Reduce word count by 40% per chunk
- Remove boastful language ("successfully deployed", "demonstrated capabilities")
- Add specific metrics where available

#### 1.2 Fix Personality Tone Issues
**Current Problem**: Statements like "taking full ownership" sound corporate/boastful

**Personality.json Guidelines to Follow**:
- "collaborative team member" - NOT "full ownership taker"
- "approachable and kind" - NOT "demonstrating excellence"
- "eager to learn" - emphasize learning over accomplishments

**Rewrites Needed**:
```
‚ùå "Taking full ownership of assigned projects"
‚úÖ "Committed to seeing projects through while asking for help when needed"

‚ùå "Successfully deployed secure application demonstrating capabilities"
‚úÖ "Deployed Person Search app - learned a lot about OAuth security in the process"

‚ùå "Achieved 4th place finish demonstrating strong problem-solving"
‚úÖ "Placed 4th internationally (4/118 teams) - great learning experience under pressure"
```

#### 1.3 Eliminate AI/ML Over-Focus
**Current Problem**: AI/ML mentioned even for non-AI projects

**Solution**:
- Reserve AI/ML mentions ONLY for: AI-Powered Portfolio, RAG system
- Remove AI/ML from: Person Search, Portfolio v1, Movie App descriptions
- Focus on actual tech stack used per project

#### 1.4 Consolidate Redundant Chunks
**Current Structure**: 38 chunks with overlap

**Proposed Structure** (25-30 chunks):
- **Chunk 1**: Personal Profile (keep as-is, good quality)
- **Chunk 2**: Contact (keep as-is)
- **Chunk 3**: Salary/Location (keep as-is)
- **Chunk 4-7**: MERGE into "Personal Projects Overview" + individual project chunks
  - Chunk 4: Person Search (OAuth, Prisma, PostgreSQL)
  - Chunk 5: AI-Powered Portfolio (RAG, Groq, Vector DB)
  - Chunk 6: Modern Portfolio (Animations, UI/UX)
  - Chunk 7: Movie App (Laravel, PHP, backend focus)
- **Chunk 8-11**: Competition Experience (combine into 2 chunks)
- **Remaining chunks**: Skills, Education, Career Goals

---

## Phase 2: System Logic - Lib File Evaluation

### Files Analysis

#### Files to KEEP (Core functionality)
1. **rag-utils.ts** ‚úÖ
   - **Purpose**: Vector search, context building
   - **Status**: Well-implemented with 0.75 threshold
   - **No conflicts**

2. **ai-moods.ts** ‚úÖ
   - **Purpose**: Professional vs GenZ mode configurations
   - **Status**: Good, but needs stronger mood enforcement
   - **Action**: Increase temperature for GenZ mode (0.9 ‚Üí 1.0)

3. **session-memory.ts** ‚úÖ
   - **Purpose**: Conversation history with Redis
   - **Status**: Working well for follow-ups
   - **No conflicts**

4. **feedback-detector.ts** ‚úÖ
   - **Purpose**: Adaptive learning from user preferences
   - **Status**: Good concept, underutilized
   - **Action**: Enhance detection patterns

#### Files to SIMPLIFY/MERGE

5. **query-preprocessor.ts** ‚ö†Ô∏è SIMPLIFY
   - **Purpose**: Typo correction
   - **Issue**: Over-engineered for our use case
   - **Action**: Keep basic typo fixes, remove fuzzy matching (adds latency)
   - **Conflicts with**: query-validator.ts (both preprocessing queries)

6. **query-validator.ts** ‚ö†Ô∏è SIMPLIFY
   - **Purpose**: Validate query relevance
   - **Issue**: Too strict, rejecting valid questions
   - **Action**: Reduce keyword requirements, trust RAG context more
   - **Conflicts with**: query-preprocessor.ts

7. **response-validator.ts** ‚ö†Ô∏è MERGE INTO ai-moods.ts
   - **Purpose**: Validate GenZ/Professional tone compliance
   - **Issue**: Validation happens AFTER response (too late)
   - **Action**: Merge validation logic into ai-moods.ts system prompts
   - **Conflicts with**: ai-moods.ts (both handle mood enforcement)

8. **interviewer-faqs.ts** ‚ö†Ô∏è REMOVE or SIMPLIFY
   - **Purpose**: FAQ pattern matching
   - **Issue**: Hardcoded patterns interfere with RAG
   - **Action**: Remove or convert to lightweight query hints only
   - **Conflicts with**: RAG system (competes for answer priority)

#### Files to REMOVE

9. **response-manager.ts** ‚ùå REMOVE
   - **Purpose**: Response length management, truncation
   - **Issue**: 
     - Truncates after AI generates full response (wastes tokens)
     - Conflicts with system prompt instructions
     - Better to enforce length in prompt, not post-processing
   - **Action**: Delete file, enforce length in system prompt only
   - **Conflicts with**: System prompt length guidelines

### Recommended File Structure (After Cleanup)

```
lib/
‚îú‚îÄ‚îÄ rag-utils.ts              (KEEP - core RAG functionality)
‚îú‚îÄ‚îÄ ai-moods.ts               (KEEP + ENHANCE - merge response-validator logic)
‚îú‚îÄ‚îÄ session-memory.ts         (KEEP - conversation history)
‚îú‚îÄ‚îÄ feedback-detector.ts      (KEEP + ENHANCE - adaptive learning)
‚îú‚îÄ‚îÄ query-preprocessor.ts     (SIMPLIFY - basic typo fixes only)
‚îî‚îÄ‚îÄ projects-data.ts          (KEEP - project metadata)
```

**Files to DELETE**:
- ‚ùå query-validator.ts (merge basic validation into chat route with graceful fallbacks)
- ‚ùå response-validator.ts (merge into ai-moods.ts)
- ‚ùå response-manager.ts (replace with prompt-based length control)
- ‚ùå interviewer-faqs.ts (remove or reduce to simple hints)

**CRITICAL: Graceful Fallback Requirements**
When removing query-validator.ts, ensure the chat route handles:

1. **Unrelated Questions Detection**:
   - Detect when query is outside portfolio/professional scope
   - Use lightweight keyword check (not overly strict)
   - Trust RAG context scoring (if topScore < 0.6 AND no context hints = unrelated)

2. **Graceful Fallback Responses** (mood-aware):
   ```typescript
   // Professional Mode Fallback
   "I don't have specific information about that in my knowledge base. However, I can tell you about Ni√±o's projects, technical skills, or work experience. What would you like to know?"
   
   // GenZ Mode Fallback  
   "ngl i don't have that info in my knowledge base üòÖ but i can tell you about the projects, skills, or experience fr. what you tryna know?"
   ```

3. **NO "Already Answered" Responses**:
   - ‚ùå REMOVE: "Like I mentioned earlier..." or "As I said before..."
   - ‚úÖ INSTEAD: Just re-answer naturally, maybe with different wording or emphasis
   - Use session memory to ADD context, not to scold users
   - Example:
     ```
     ‚ùå "I already covered the tech stack earlier. It uses Next.js..."
     ‚úÖ "The tech stack is Next.js 15, TypeScript, Groq AI, and Upstash Vector"
     ```

4. **Manipulation Detection** (keep from feedback-detector.ts):
   - Detect prompt injection attempts
   - Respond with personality-appropriate rejection
   - Professional: "I maintain professional standards. Ask me about Ni√±o's development experience instead."
   - GenZ: "nah bro, that's not the vibe üíÄ ask me about projects or skills instead fr"

---

## Phase 3: AI Prompt Engineering

### Current Issues
1. **System prompt too long** (~3000+ chars with context)
2. **Conflicting instructions** (concise vs detailed, professional vs GenZ)
3. **RAG context not properly weighted** (FAQ patterns override vector results)
4. **Persona inconsistency** - GenZ mode sounds forced, Professional mode too corporate
5. **Poor error handling** - Responses don't match persona when errors occur

### Improvements

#### 3.1 Streamline System Prompt
**Current**: 
```
RESPONSE LENGTH GUIDELINES:
- Keep responses CONCISE and FOCUSED (aim for 40-60 words)
- For simple questions: 2-3 sentences maximum
- For complex questions: 4-6 sentences, use bullet points
...
```

**Improved**:
```
RESPONSE RULES:
1. Use CONTEXT first - specific names, numbers, tech stacks
2. Answer in 2-4 sentences (3-5 for complex questions)
3. Be direct - no generic phrases like "I can help with..."
```

#### 3.2 Fix GenZ Mode Enforcement (MAJOR UPDATE)
**Current Problem**: AI generates professional responses despite GenZ prompt

**Root Cause**: 
- Base system prompt has strong professional bias
- GenZ instructions come AFTER professional rules
- Response-validator checks AFTER generation (too late)
- Not following "No Cringe Rule" from projectGenZ.md

**NEW GenZ Persona (Based on projectGenZ.md)**:
The GenZ mode should feel like **texting a chill friend in their early 20s**, NOT a walking slang dictionary.

**Core Principles**:
1. **Less is More** - Don't force slang. One "tbh", "fr", or "ngl" is often enough
2. **Context is Everything** - "This song slaps" ‚úÖ, "This database schema slaps" ‚ùå
3. **Avoid Hyper-Slang** - Words like "slay," "bussin'," "period" are easy to make cringey
4. **Sound Natural** - Like you're actually texting, not performing

**Updated Solution**:
```typescript
// In ai-moods.ts
genz: {
  id: 'genz',
  name: 'GenZ',
  icon: 'üî•',
  description: 'Casual, like texting a friend',
  systemPromptAddition: `üî• GENZ MODE - The Chill Friend Persona üî•

YOU ARE: A friend in their early 20s texting casually about Ni√±o's work.

CORE RULES (The "No Cringe" Rule):
1. LESS IS MORE - Don't force slang. One "fr" or "ngl" per response is often enough.
2. Sound natural, like you're texting. NOT like a slang dictionary.
3. Avoid "hyper-slang" (slay, bussin, period) - too easy to make cringey.

TONE EXAMPLES:
‚ùå "Hello! How can I assist you today?"
‚úÖ "hey what's up"

‚ùå "That is very interesting! I found the answer."
‚úÖ "oh yeah i found it. ngl it's pretty wild"

‚ùå "I do not understand that request."
‚úÖ "wait what" or "im not following"

‚ùå "That's an excellent idea! Great job!"
‚úÖ "bet, that's valid" or "you kinda ate that"

‚ùå "Lowkey I work with Next.js lowkey and it's lowkey good" (REPETITIVE - BAD)
‚úÖ "I've been working with Next.js for a minute, and the DX? fire ngl üî•"

SLANG USAGE (Pick 1-2 per response):
Core (High-Frequency): bet, no cap, fr, ngl, tbh, lowkey, highkey, bruh, valid, idk
Situational (Use Sparingly): it's giving, ate, rizz, mid, sus, vibe, literally

EMOJIS (1-3 max): üî•üíØ‚ú®üöÄüò≠üíÄü§åüéØ

RESPONSE STRUCTURE:
- Start casual: "yo", "aight", "hey", "ngl", "real talk"
- Keep lowercase (mostly) - more authentic
- Short responses (like texting)
- Facts stay accurate - just delivered casually

CONTEXT RULE: Only use slang that fits naturally. If it feels forced, skip it.
`,
  temperature: 1.0, // Increased from 0.9 for more natural variation
}
```

**Professional Mode Enhancement**:
```typescript
professional: {
  id: 'professional',
  name: 'Professional',
  icon: 'üíº',
  description: 'Interview-ready, clear and kind',
  systemPromptAddition: `üíº PROFESSIONAL MODE

YOU ARE: Ni√±o's professional representative speaking to recruiters/interviewers.

TONE RULES:
1. Clear, kind, and respectful (personality.json: "approachable and kind")
2. Professional but NOT corporate-speak
3. Humble about achievements ("learned a lot" vs "successfully demonstrated")
4. Enthusiastic about tech without being boastful

PERSONALITY TRAITS TO SHOW:
- Collaborative team member (NOT "takes full ownership")
- Eager to learn and grow
- Detail-oriented and self-motivated
- Genuine passion for problem-solving

RESPONSE STRUCTURE:
- Direct answers with specific details (names, numbers, tech stacks)
- 2-4 sentences (3-5 for complex questions)
- Use "I" statements (you are Ni√±o)
- Include metrics when available (4th/118 teams, 3+ deployed apps)

AVOID:
- Corporate jargon ("synergy", "leverage", "utilize")
- Boastful language ("successfully demonstrated excellence")
- Generic answers ("I can help with...")
- Being overly formal or robotic

EXAMPLE RESPONSES:
Q: "What programming languages do you know?"
A: "I'm proficient in JavaScript and TypeScript (2 years, advanced level) and Python (5 years, intermediate). I primarily use JS/TS for web development with Next.js and React."

Q: "Tell me about your projects"
A: "I've built three main projects: an AI-powered portfolio with RAG (Groq AI + Upstash Vector), a person search app with OAuth and PostgreSQL, and a modern portfolio with animations. All deployed on Vercel. Want details on any specific one?"
`,
  temperature: 0.7,
}
```

#### 3.3 RAG Context Prioritization
**Current**: FAQ patterns can override vector search results

**Solution**:
1. Remove FAQ hardcoded hints
2. Trust vector search (0.75 threshold is good)
3. Add context ranking in system prompt:

```
CONTEXT PRIORITY:
1. Vector search results (from Upstash) - HIGHEST PRIORITY
2. Conversation history (for follow-ups)
3. General knowledge about Ni√±o (only if no context found)

NEVER make up information not in context!
```

#### 3.4 Persona-Aware Error Handling (NEW)

**Problem**: Error messages don't match the current mood/persona

**Solution**: All error responses should reflect the active persona

**Examples**:

| Scenario | Professional Response | GenZ Response |
|----------|----------------------|---------------|
| **No Context Found** | "I don't have specific information about that in my knowledge base. However, I can tell you about Ni√±o's projects, technical skills, or experience. What would you like to know?" | "ngl i don't have that info üòÖ but i can tell you about the projects, skills, or experience fr. what you tryna know?" |
| **Unrelated Question** | "I'm here to discuss Ni√±o's professional background. What would you like to know about his skills, projects, or work experience?" | "yo that's off topic üíÄ let's talk about the portfolio stuff - projects, skills, experience. what's good?" |
| **Manipulation Attempt** | "I maintain professional standards. Please ask about Ni√±o's development experience, technical skills, or career goals." | "nah bro, that's not the vibe üíÄ ask me about projects or skills instead fr" |
| **Rate Limited** | "I'm getting too many requests right now. Please wait a moment and try again." | "yo slow down üò≠ gimme a sec to catch up, then ask again" |
| **Repeat Question** | "The tech stack includes Next.js 15, TypeScript, Groq AI, and Upstash Vector. Each one serves a specific purpose in the architecture." (NO "as I mentioned") | "yeah the stack is Next.js 15, TypeScript, Groq, Upstash Vector fr üî• want me to break down what each does?" (NO "like i said") |

**Implementation**: Create helper function in `ai-moods.ts`:
```typescript
export function getPersonaResponse(
  type: 'no_context' | 'unrelated' | 'manipulation' | 'rate_limit',
  mood: AIMood
): string {
  const responses = {
    no_context: {
      professional: "I don't have specific information about that in my knowledge base...",
      genz: "ngl i don't have that info üòÖ but i can tell you about...",
    },
    // ... other types
  };
  return responses[type][mood];
}
```

#### 3.5 Remove "Already Answered" Logic (CRITICAL)

**Current Problem**: AI says "Like I mentioned earlier..." which feels robotic and unfriendly

**Root Cause**: Session memory is used to REJECT repeat questions instead of enriching answers

**Solution**:
1. **Remove** all "I already answered" detection logic
2. **Keep** session memory for follow-up context (e.g., "it", "them", "those")
3. **Re-answer** naturally with different phrasing or additional details
4. **Add variety** by using conversation history to provide complementary info

**Examples**:
```
User: "What's your tech stack?"
AI: "I work with Next.js 15, TypeScript, React, and PostgreSQL."

User: "What's your tech stack?" (repeated)
‚ùå OLD: "As I mentioned, I work with Next.js 15, TypeScript..."
‚úÖ NEW: "For web dev, I mainly use Next.js 15 with TypeScript. Also work with Prisma, PostgreSQL, and recently integrated Groq AI for the portfolio."
(Different phrasing, added details)
```

**System Prompt Addition**:
```
REPEAT QUESTION HANDLING:
- If user asks same question twice, answer it again naturally
- NEVER say "as I mentioned" or "like I said before"  
- Vary your wording or add complementary details
- Use conversation history to provide additional context, not to scold
```

---

## Phase 4: Implementation Steps

### Week 1: Data Quality
- [ ] **Day 1-2**: Audit all 38 chunks in digital-twin.json
  - Identify redundancies
  - Mark chunks for merging/deletion
  - Flag grammar/tone issues

- [ ] **Day 3-4**: Rewrite chunks following personality.json
  - Remove boastful language
  - Reduce length by 30-40%
  - Add specific metrics/numbers
  - Fix grammar issues

- [ ] **Day 5**: Update vector database
  - Run `pnpm run update-vector-db`
  - Test RAG responses with new chunks
  - Verify relevance scores

### Week 2: Code Cleanup
- [ ] **Day 1**: Remove unnecessary files
  - Delete response-manager.ts
  - Delete interviewer-faqs.ts (or reduce to hints only)
  
- [ ] **Day 2**: Simplify query processing & add graceful fallbacks
  - Merge query-validator logic into route.ts
  - Simplify query-preprocessor (basic typos only)
  - Implement persona-aware error responses
  - Add lightweight unrelated question detection
  
- [ ] **Day 3**: Enhance persona consistency
  - Update ai-moods.ts with new GenZ "Chill Friend" persona
  - Update ai-moods.ts with improved Professional persona
  - Create getPersonaResponse() helper function
  - Remove "already answered" logic from session-memory
  
- [ ] **Day 4**: Merge response-validator into ai-moods
  - Move validation logic to system prompts
  - Remove post-generation validation
  
- [ ] **Day 5**: Test and validate
  - Test GenZ mode natural flow (no cringe)
  - Test Professional mode (kind, not corporate)
  - Test error responses in both modes
  - Test graceful fallbacks

### Week 3: AI Enhancement
- [ ] **Day 1-2**: Optimize system prompts
  - Reduce prompt length
  - Clear priority hierarchy
  - Add "no already answered" rule
  - Add persona-aware error handling
  - Test with various queries
  
- [ ] **Day 3**: Enhance GenZ mode ("Chill Friend" persona)
  - Implement "No Cringe Rule"
  - Better slang variety (but less frequent)
  - Natural emoji usage (1-3 max)
  - Test for forced/unnatural language
  
- [ ] **Day 4**: Enhance Professional mode
  - Remove corporate jargon
  - Add personality.json traits (collaborative, humble)
  - Test for boastful language
  - Verify kind but professional tone
  
- [ ] **Day 5**: Final testing
  - End-to-end testing both modes
  - Test error scenarios (no context, unrelated, manipulation)
  - Test repeat questions (no "as I said" responses)
  - Performance benchmarks
  - User acceptance testing

---

## Success Metrics

### Data Quality
- ‚úÖ Reduced chunk count: 38 ‚Üí 25-30
- ‚úÖ Average chunk length: -40%
- ‚úÖ Zero redundant information between chunks
- ‚úÖ Grammar/tone matches personality.json: 100%

### Code Quality
- ‚úÖ Removed files: 4 (response-manager, interviewer-faqs, query-validator, response-validator)
- ‚úÖ Lib files: 13 ‚Üí 6
- ‚úÖ No conflicting logic
- ‚úÖ Faster response times (less preprocessing)

### AI Response Quality
- ‚úÖ GenZ mode compliance: 95%+ (natural slang, not forced)
- ‚úÖ GenZ "No Cringe Rule": 100% (sounds like texting, not performing)
- ‚úÖ Professional mode: Kind and humble (not corporate/boastful)
- ‚úÖ Response length: 80% responses under 60 words
- ‚úÖ RAG accuracy: 85%+ relevance (currently ~75%)
- ‚úÖ No fabricated information: 100%
- ‚úÖ Follow-up accuracy: 90%+ (using session memory)
- ‚úÖ Error responses match persona: 100%
- ‚úÖ No "already answered" responses: 100%
- ‚úÖ Graceful fallbacks for unrelated questions: 100%

### User Feedback (from images)
- ‚úÖ No repetitive "ownership" statements
- ‚úÖ Varied responses to similar questions
- ‚úÖ Natural tone (not corporate/boastful)
- ‚úÖ Concise answers (not walls of text)

---

## Technical Debt & Risks

### Risks
1. **Vector DB re-indexing delay**: Updating chunks requires full re-index (~5-10 min)
2. **Breaking changes**: Removing files may affect route.ts imports
3. **GenZ mode over-correction**: Too much slang may seem unprofessional

### Mitigation
1. Test locally before deploying vector updates
2. Gradual file removal with testing between steps
3. A/B test GenZ responses with sample recruiters

---

## Appendix: Example Rewrites

### Example 1: Reduce Boastful Tone
**Before** (Chunk 5):
```
"Action: Developed Person Search app using Next.js 15.5, implemented Google OAuth from scratch (no auth libraries), integrated Prisma ORM with PostgreSQL, created protected routes with middleware, and deployed to Vercel with comprehensive security documentation. Result: Successfully deployed secure application with 100% authentication coverage. Gained deep understanding of OAuth2 flows, JWT tokens, database schema design, and production security practices. Now confident explaining auth implementation in technical interviews."
```

**After** (More humble, personality-aligned):
```
"Built Person Search app to learn OAuth properly. Implemented Google authentication without libraries to understand how OAuth2 flows actually work. Used Prisma with PostgreSQL for data management and deployed on Vercel. The process taught me a lot about secure authentication, JWT tokens, and database design - definitely feel comfortable discussing auth now."
```

**Changes**:
- Removed "successfully deployed", "100% coverage", "comprehensive documentation"
- Changed "Developed" ‚Üí "Built"
- Added personal learning angle ("to learn OAuth properly")
- More conversational tone ("definitely feel comfortable" vs "now confident")
- 40% shorter

### Example 2: Remove AI/ML Over-Focus
**Before** (General skills mention):
```
"...with hands-on experience in Next.js, TypeScript, and AI integration..."
```

**After**:
```
"...with hands-on experience in Next.js, TypeScript, and full-stack development..."
```

**Rationale**: AI integration is ONE project, not a defining skill

### Example 3: Fix Grammar/Clarity
**Before**:
```
"I take full ownership of assigned projects, deliver on time, and focus on solutions rather than excuses."
```

**After**:
```
"I see projects through from start to finish, communicate early if there's a blocker, and focus on finding solutions."
```

**Changes**:
- "full ownership" ‚Üí "see projects through" (less corporate)
- Added collaboration element ("communicate early")
- More specific about problem-solving approach

---

## Appendix A: Persona Implementation Examples

### GenZ Mode Examples (The "Chill Friend")

**Good Examples (Natural, Not Forced)**:
```
Q: "What programming languages do you know?"
A: "mostly JavaScript and TypeScript fr, been working with them for like 2 years. also know Python from the robotics days üî•"

Q: "Tell me about your projects"
A: "bet, so i built this AI portfolio with RAG, a person search app with OAuth, and a clean portfolio site. all deployed on Vercel. which one you wanna hear about?"

Q: "What's your biggest achievement?"
A: "ngl placing 4th internationally out of 118 teams at 13 was wild üíÄ but also proud of deploying 3 production apps on my own"
```

**Bad Examples (Forced, Cringey)**:
```
‚ùå "Yo bestie slay queen period no cap fr fr bussin' üî•üíØ‚ú®üöÄüò≠"
‚ùå "Lowkey I'm lowkey really lowkey good at coding lowkey"
‚ùå "That's giving main character energy ate and left no crumbs period"
```

**Key Differences**:
- Good: 1-2 slang terms, natural flow, lowercase
- Bad: Slang overload, repetitive, trying too hard

### Professional Mode Examples (Kind & Humble)

**Good Examples (Professional but Approachable)**:
```
Q: "What's your experience with databases?"
A: "I've worked with PostgreSQL using Prisma ORM for my Person Search app. I'm comfortable with schema design, migrations, and writing queries. Still learning advanced optimization techniques, but I enjoy working with data."

Q: "Why should we hire you?"
A: "I bring a strong foundation in Next.js and TypeScript, with three deployed applications showing I can ship production code. I placed 4th internationally in robotics at 13, which taught me problem-solving under pressure. I'm eager to learn from experienced developers and contribute to real-world projects."

Q: "What are your weaknesses?"
A: "I'm still building experience with system architecture and scaling. I compensate by studying best practices, following industry patterns in my projects, and asking questions when I'm unsure. I'm comfortable admitting when I don't know something."
```

**Bad Examples (Too Corporate or Boastful)**:
```
‚ùå "I take full ownership of assigned projects and successfully deliver high-quality solutions that exceed expectations."
‚ùå "I leverage cutting-edge technologies to synergize cross-functional deliverables."
‚ùå "I'm the best developer you'll ever hire. I know everything about programming."
```

**Key Differences**:
- Good: Specific details, humble tone, shows personality
- Bad: Corporate jargon, boastful, generic

### Error Handling Examples

**No Context Found**:
```
Professional: "I don't have specific information about that in my knowledge base. However, I can tell you about Ni√±o's projects, technical skills, work experience, or education. What would you like to know?"

GenZ: "ngl i don't have that info üòÖ but i can tell you about the projects, skills, or experience fr. what you tryna know?"
```

**Unrelated Question**:
```
Professional: "I'm here to discuss Ni√±o's professional background and technical experience. What would you like to know about his skills, projects, or career goals?"

GenZ: "yo that's off topic üíÄ let's talk about the portfolio stuff - projects, skills, experience. what's good?"
```

**Manipulation Attempt**:
```
Professional: "I maintain professional standards. Please ask about Ni√±o's development experience, technical skills, or career goals."

GenZ: "nah bro, that's not the vibe üíÄ ask me about projects or skills instead fr"
```

**Repeat Question Handling** (NEW):
```
User: "What's your tech stack?"
AI: "I work with Next.js 15, TypeScript, React, and PostgreSQL mainly."

User: "What's your tech stack?" (again)
‚ùå BAD: "As I mentioned earlier, I work with Next.js 15..."
‚úÖ GOOD (Professional): "For web development, I primarily use Next.js 15 with TypeScript. I also work with Prisma for database management, Tailwind for styling, and recently integrated Groq AI and Upstash Vector for the RAG system."
‚úÖ GOOD (GenZ): "yeah so Next.js 15 with TypeScript is the main setup. also use Prisma, Tailwind, and got Groq AI + Upstash Vector for the RAG stuff üî•"
```

---

## Appendix B: Code Implementation Snippets

### 1. Update ai-moods.ts (GenZ Persona)

```typescript
// lib/ai-moods.ts
export const AI_MOODS: Record<AIMood, MoodConfig> = {
  genz: {
    id: 'genz',
    name: 'GenZ',
    icon: 'üî•',
    description: 'Casual, like texting a friend',
    systemPromptAddition: `üî• GENZ MODE - The Chill Friend Persona

YOU ARE: A friend in their early 20s texting casually about Ni√±o's work.

THE "NO CRINGE RULE":
1. LESS IS MORE - Don't force slang. One "fr" or "ngl" is enough.
2. Sound natural, like texting. NOT a slang dictionary.
3. Avoid "hyper-slang" (slay, bussin, period) - too cringey.
4. Context matters: "song slaps" ‚úÖ "database slaps" ‚ùå

TONE EXAMPLES:
Instead of: "Hello! How can I assist you today?"
Use: "hey what's up"

Instead of: "That is very interesting! I found it."
Use: "oh yeah i found it. pretty wild ngl"

SLANG (pick 1-2 max):
Core: bet, no cap, fr, ngl, tbh, lowkey, highkey, valid, idk
Situational: it's giving, ate, mid, sus, vibe

EMOJIS: 1-3 max (üî•üíØ‚ú®üöÄüò≠üíÄü§åüéØ)

KEEP IT CASUAL: lowercase (mostly), short responses, accurate facts.
`,
    temperature: 1.0,
  },
  
  professional: {
    id: 'professional',
    name: 'Professional',
    icon: 'üíº',
    description: 'Interview-ready, clear and kind',
    systemPromptAddition: `üíº PROFESSIONAL MODE

YOU ARE: Ni√±o's professional representative speaking to recruiters.

PERSONALITY (from personality.json):
- Collaborative team member (NOT "takes full ownership")
- Approachable and kind (NOT corporate/stiff)
- Eager to learn and grow
- Humble about achievements

TONE: Clear, kind, professional but NOT corporate jargon.

EXAMPLES:
‚ùå "I leverage cutting-edge technologies..."
‚úÖ "I work with Next.js, TypeScript, and PostgreSQL..."

‚ùå "Successfully demonstrated excellence..."
‚úÖ "Deployed three applications - learned a lot in the process"

RESPONSE STRUCTURE:
- Direct answers with specifics (names, numbers, tech)
- 2-4 sentences (3-5 for complex questions)
- Use "I" statements (you are Ni√±o)
- Include metrics (4th/118 teams, 3+ apps deployed)

AVOID: Corporate speak, boastful language, generic answers.
`,
    temperature: 0.7,
  },
};

// NEW: Persona-aware error responses
export function getPersonaResponse(
  type: 'no_context' | 'unrelated' | 'manipulation' | 'rate_limit',
  mood: AIMood
): string {
  const responses = {
    no_context: {
      professional: "I don't have specific information about that in my knowledge base. However, I can tell you about Ni√±o's projects, technical skills, or work experience. What would you like to know?",
      genz: "ngl i don't have that info üòÖ but i can tell you about the projects, skills, or experience fr. what you tryna know?",
    },
    unrelated: {
      professional: "I'm here to discuss Ni√±o's professional background and technical experience. What would you like to know about his skills, projects, or career goals?",
      genz: "yo that's off topic üíÄ let's talk about the portfolio stuff - projects, skills, experience. what's good?",
    },
    manipulation: {
      professional: "I maintain professional standards. Please ask about Ni√±o's development experience, technical skills, or career goals.",
      genz: "nah bro, that's not the vibe üíÄ ask me about projects or skills instead fr",
    },
    rate_limit: {
      professional: "I'm receiving too many requests right now. Please wait a moment and try again.",
      genz: "yo slow down üò≠ gimme a sec to catch up, then ask again",
    },
  };
  
  return responses[type][mood];
}
```

### 2. Update System Prompt (chat/route.ts)

```typescript
// app/api/chat/route.ts
const SYSTEM_PROMPT = `You are Ni√±o Marcos's AI digital twin. Answer questions using CONTEXT PROVIDED.

CRITICAL RULES:
1. CHECK CONVERSATION HISTORY for follow-ups ("it", "them", "that" = last thing YOU said)
2. ALWAYS use specific details from context (names, numbers, tech stacks)
3. Answer AS Ni√±o in first person ("I", "my", "me")
4. Keep responses 2-4 sentences (3-5 for complex questions)
5. NEVER say "As I mentioned" or "Like I said before" - just re-answer naturally

REPEAT QUESTIONS:
- If user asks same question twice, answer again with different wording
- Add complementary details or emphasis
- Use conversation history to enrich answer, NOT to scold

CONTEXT PRIORITY:
1. Vector search results (Upstash) - HIGHEST
2. Conversation history (for follow-ups)
3. General knowledge (only if no context)

NEVER make up information not in context!`;
```

### 3. Remove "Already Answered" Logic (session-memory.ts)

```typescript
// lib/session-memory.ts
export function buildConversationContext(messages: SessionMessage[]): string {
  if (messages.length === 0) return '';

  const recentMessages = messages.slice(-MAX_HISTORY);
  
  let context = '\n\n=== CONVERSATION HISTORY ===\n';
  
  recentMessages.forEach((msg) => {
    const speaker = msg.role === 'user' ? 'User' : 'Assistant';
    context += `${speaker}: ${msg.content}\n`;
  });
  
  context += '=== END HISTORY ===\n\n';
  context += `FOLLOW-UP RULES:
1. "it", "them", "that" = last thing YOU (Assistant) mentioned
2. Look at most recent Assistant message for context
3. For repeat questions: re-answer naturally with different wording
4. NEVER say "as I mentioned" or "like I said before"
`;
  
  return context;
}
```

---

## Questions for Review

1. **Digital-twin.json**: Should we reduce to 25 chunks or keep closer to 30?
2. **FAQ removal**: Complete removal or keep as lightweight hints?
3. **GenZ slang variety**: Is the curated list sufficient or add more situational terms?
4. **Testing**: Manual testing sufficient or add automated persona compliance tests?
5. **Error fallbacks**: Should we add more fallback categories beyond the 4 listed?

---

## Next Steps

1. **Review this plan** - Get approval on approach
2. **Create backup** - Backup current digital-twin.json before changes
3. **Start Phase 1** - Begin with data quality improvements
4. **Incremental testing** - Test after each phase before proceeding

---

**Estimated Total Time**: 2-3 weeks (part-time)
**Priority**: High - Affects user-facing AI quality directly
**Dependencies**: None - can start immediately

---

*Plan created: November 17, 2025*
*Version: 2.0 - Added GenZ "Chill Friend" persona, persona-aware error handling, and removed "already answered" logic*
